---
title: "Effect of Median Age on Total Health Spending"
author: "David Ballester, Dylan Le, Nathan Spiess, Tyler Stoen"
format: 
  html:
    self-contained: true
    code-tools: true
    toc: true
    number-sections: true
    code-fold: true
editor: source
execute: 
  error: true
  echo: true
  message: false
  warning: false
---

Load Packages
```{r}
library(tidyverse)
library(here)
library(moderndive)
library(broom)
library(patchwork)
```

## Reading and Cleaning Data
```{r}
# Read in data
age <- read.csv("/Users/dylanle/Desktop/stat331/stat331-final-project/median_age_years.csv")
health <- read.csv("/Users/dylanle/Desktop/stat331/stat331-final-project/total_health_spending_per_person_us.csv")
```
We will be using the two quantitative variables, total health spending per person in USD and median age, all of which came from Gapminder.

Our response variable will be Total health spending / person USD which can be described as the average amount spent per person in USD for every country from 1994 to 2009 according to the World Health Organization.

Our observational variable will be the median age of the total population in each country since 1949. It also includes predicted median age until 2099.

We expect the relationship between average spending per person and median age to be positive because as the population becomes increasingly older on average, people will require more medical attention. We would also expect both the total health spending per person and the median age to increase with time.


Some cleaning needed to be done in order to make the data easier to work with.

```{r}
age_long <- age |>
  pivot_longer(cols = X1949:X2099,
               names_to = "year",
               values_to = "median_age") |>
  mutate(year = as.integer(str_sub(year, 2)))

health_long <- health |>
  pivot_longer(cols = X1994:X2009,
               names_to = "year",
               values_to = "healthCost") |>
  mutate(year = as.integer(str_sub(year, 2)))
```
Because the variable name started with a number, "X" was added before each year automatically by R. As a consequence, the year was changed into a categorical variable. Thus, after pivoting, I removed the "X" from each year and converted it into an integer.

```{r}
ageHealth <- health_long |>
  left_join(age_long, by = c("country", "year"))
```
We decided to perform a left join between health_long and age_long, since the total health spending has less observation, and in turn, decrease the amount of missing values.

## Linear Regression
First, we will create a scatterplot to see the relationship between total health spending per person and median age.
```{r}
ageHealth |>
  ggplot(aes(y=healthCost,
             x=median_age)) +
  geom_jitter(width = 0.25, height = 0.5) +
  labs(title = "Figure 1: Total Health Spending vs. Median Age",
       subtitle = "Health Spending (USD)",
       x = "Median Age (years)",
       y = "") +
  geom_smooth(method = "lm") +
  theme_bw()
```
Based on Figure 1, our assumption was correct and there does appear to be a positive correlation between amount spent on health and median age. As the median age increases, the average amount spent on health does as well, which agrees with our hypothesis. Although the correlation appears to be positive, it does not appear linear. One reason this could occur is that total health care spending is bounded at 0. This is likely because many countries are less wealthy, so they may not be able to spend money on these healthcare products. Even as age increases, citizens in various simply can't afford or don't have the resources to spend more money per person on healthcare. We ca see this where many values hover near 0 in age ranges from 15 to 40. Conversely, other countries overcharge citizens on healthcare, which leads to many points deviating heavily from the regression line. The combination of many points hovering near $0 spent per person on health care and these sharp increases from countries that overcharge create a nonlinear relationship.

Now, let's examine this relationship overtime.
```{r}
ageHealth |>
  group_by(year) |>
  ggplot(aes(y=healthCost,
             x=median_age)) +
  geom_jitter(width = 0.25, height = 0.5) + 
  facet_wrap(~year) +
  labs(title = "Figure 2: Total Health Spending vs. Median Age From 1994-2009",
       subtitle = "Health Spending per person",
       x = "Median Age (years)",
       y = "") +
  geom_smooth(method = "lm") +
  theme_bw()
```
In order to see the how the relationship has changed over time, we faceted the graph by year (Figure 2). Here, we can see that as time passes, there appears to be a more positive relationship between total health spending per person and median age of a country. This is indicated by the slope of the regression lines on each graph becoming more noticeably steeper. This is likely due to inflation, where as products get more expensive, people will be forced to spend more money on it.

Although the data do not seem to be following a linear relationship based on the data visualizations above, we will use a linear relationship for the purposes of the project.

Now, we will fit a linear model model to the data.
```{r}
model <- lm(healthCost ~ median_age,
            data = ageHealth)

```

We are fitting a linear relationship using median age to predict total health spending per person, where the x variable is median age and the y variable is the predicted total health spending per person.
```{r}
knitr::kable(tidy(model), 
             "html",
             caption = "Table 1: Linear Regression Model of Total Healthcare 
             Spending per Person (USD) vs Median age")
```
Model:
predicted total health spending / person = -1744.56 + 95.45(median age)

For every one year increase in median age, there is a 95.45 USD increase in the mean expected total health spending per person. A country with median age 0 has an expected mean total health spending per person of -1744.56 USD. Because the intercept value of -1744.56 is negative, this indicates that the regression equation would be poor at making predictions at smaller ages. This is because it is nonsensical to have a negative total spending. However, this negative intercept is necessary in order to fit all of the data best.

Now, let's see how well the regression equation fits the data.
```{r}
var <- model |>
  get_regression_points() |>
  summarize(SSTotal = var(healthCost),
            SSModel = var(healthCost_hat),
            SSError = var(residual)) |>
  mutate(rsquare = SSModel/SSTotal)

knitr::kable(var, 
             "html",
             caption = "Table 2: Variance of Linear Regression Model",
             col.names = c("SSTotal", "SSModel", "SSError", "R Squared")
             )
```
SSTotal is a measure of the total variation in the dataset. SSModel is a measure of the variation in total health care costs per person that is explained by the regression line. SSError is a measure of the variation in the dependent variable that is not explained the model. R^2^ is a proportion of the variation in the dependent variable that can be explained by the independent variable, and it can be found by dividing the SSModel by the SSTotal.

In Table 2, we can see that 40.5% of the variation in total healthcare costs per person is explained by the median age of the country. The R^2^ value is moderately large, which indicates our model has an adequate fit when comparing total healthcare costs and median age.This makes sense becauses in Figure 1, we can see many points are still condensed near the linear regression line, indicating some fit, but high outliers where the total spending per person is greater than $4,000 demonstrates some of data not fitting as well.

## Assessing the Model through Simulation
First, we will simulate other samples of the data. We will do this by adding "noise" to the data by taking each data point, simulating some error from a normal distribution, and adding to the data point to get a new distribution.
```{r}
model_predict <- predict(model)
model_sigma <- sigma(model)

noise <- function(x, mean = 0, sd){
  x + rnorm(length(x), 
            mean, 
            sd)
}

sim_response <- tibble(sim_healthCost = noise(model_predict, 
                                           sd = model_sigma)
                   )

sim_data <- ageHealth |> 
  filter(!is.na(healthCost), 
         !is.na(median_age)
         ) |> 
  select(healthCost, median_age) |> 
  bind_cols(sim_response)
```

Now, we will see how the simulated data compares to our observed values. We will do this by creating a scatterplot of both relationships.
```{r}
obs_reg_p <- ageHealth |>
  ggplot(aes(y=healthCost,
             x=median_age)) +
  geom_point() +
  labs(title = "Figure 1: Total Health Spending vs. Median Age",
       subtitle = "Health Spending (USD)",
       x = "Median Age (years)",
       y = "") +
  geom_smooth(method = "lm") +
  theme_bw()

sim_reg_p <-sim_data |>
  ggplot(aes(y=sim_healthCost,
             x=median_age)) +
  geom_point() +
  labs(title = "Figure 3: Simulated Total Health Spending vs. Median Age",
       subtitle = "Simulated Health Spending (USD)",
       x = "Median Age (years)",
       y = "") +
  geom_smooth(method = "lm") +
  theme_bw()



obs_reg_p + sim_reg_p

```
Based on the side by side plots above, our observed data appears to have a much more exponential form compared to our simulated data. Another major difference is that in our simulated data, there are negative values for the simulated health spending, but it isn't possible to spend negative money on something, so our observed data does not go below 0 in terms of health spending. 

Figures 1 and 3 appear to have the same regression lines, but the residuals, or differences between the observed values and predicted values on the regression line, from each graph appear to differ. In our observed data in Figure 1, there appears to be a higher count negative residuals, but it's smaller in magnitude, indicated by many of the points being closer to line. Conversely, there are a fewer quantity of positive residual values, which are values above the regression line, but there are a farther distance away. In figure 3, the positive and negative residuals appear to be evenly dispersed, where most are concentrated near the regression line and is evenly distributed as it gets further from the line. This indicates potential evidence that our observed data doesn't follow a normal distribution. 

Finally, let's see how our observed data matches the predicted values if we simulate it many times. We will do this by finding the R^2^ values of 1000 simulated models. The R^2^ value indicates how well the assumed model can produce data that is similar to the observed values. The greater the R^2^ value, the more similar the model is to our data.
```{r}
nsims <- 1000
sims <- map_dfc(.x = 1:nsims,
                .f = ~ tibble(sim = noise(model_predict, 
                                          sd = model_sigma)
                              )
                )

colnames(sims) <- colnames(sims) |> 
  str_replace(pattern = "\\.\\.\\.",
                  replace = "_")

sims <- ageHealth |> 
  filter(!is.na(healthCost), 
         !is.na(median_age)
         ) |> 
  select(healthCost, median_age) |> 
  bind_cols(sims)

sim_r_sq <- sims |> 
  map(~ lm(healthCost ~ .x, data = sims)) |> 
  map(glance) |> 
  map_dbl(~ .x$r.squared)
sim_r_sq <- sim_r_sq[names(sim_r_sq) != "healthCost"]

tibble(sims= sim_r_sq) |> 
  ggplot(aes(x = sims)) + 
  geom_histogram(binwidth = 0.01) +
  xlim(0.125, 0.2) +
  labs(x = expression("Simulated"~ R^2),
       y = "",
       title = "Figure 4: R-Squared Values from Simulated Models",
       subtitle = "Number of Simulated Models") +
  theme_bw()
```
Based on Figure 4, we see that our values ranged from 0.13 to 0.19, with the majority of the R^2^ values range between 0.16 and 0.17. This means that on average, the simulated data accounts for approximately 16% of the variability in the observed total healthcare spending per person. This means that the simulated data from the model is not very similar to what was observed, indicating a weak model.